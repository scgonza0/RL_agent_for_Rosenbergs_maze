{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Copia de Copia de maze with lot of variables",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KZTMUo8cEmf"
      },
      "source": [
        "#Enviroment class\n",
        "\n",
        "import sys\n",
        "from contextlib import closing\n",
        "from io import StringIO\n",
        "from gym import utils\n",
        "from gym.envs.toy_text import discrete\n",
        "import numpy as np\n",
        " \n",
        " \n",
        "from random import seed\n",
        "from random import randint\n",
        " \n",
        "\n",
        "\n",
        "# maze construction:\n",
        "# '|' and '-'are walls, '+'are junctions\n",
        "# ':' are spaces not available\n",
        "# 'H' is home and 'W' is the place with 'water'\n",
        "#  'Food' is in the house.\n",
        "# The agent needs to press a button to access water and food\n",
        "# The agent jumps every two places when moving horizontally or vertically.\n",
        "\n",
        "\n",
        "MAP = [                                                                                                                                                                                       \n",
        "    \"+---------------------------------+\",\n",
        "    \"|1:3:5:7:9:1:3:5:7:9:1:3:5:7:9:1:3|\",    \n",
        "    \"| +-----+ +-----+ +-----+ +-----+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#3= 3,5,7,11,13,15,19,21,23,27,29,31 -\n",
        "    \"| +-+ +-+-+-+ +-+ +-+ +-+-+-+ +-+ |\",    \n",
        "    \"|   | : : : : |     | : : : : |   |\",#5= 5,7,9,11,13,21,23,25,27,29 -\n",
        "    \"| +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#7= 3,5,7,9,11,13,15,19,21,23,25,27,29,31 +  \n",
        "    \"| +-----+ +-----+-+-----+ +-----+ |\",    \n",
        "    \"|       | : : : : : : : : |       |\",#9= 9,11,13,15,17,19,21,23,25 -   \n",
        "    \"| +-----+ +-----+ +-----+ +-----+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#11= 3,5,7,9,11,13,15,17,19,21,23,25,27,29,31 +   \n",
        "    \"| +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ |\",    \n",
        "    \"|   | : : : : | | | | : : : : |   |\",#13= 5,7,9,11,13,17,21,23,25,27,29 +  \n",
        "    \"| +-+ +-+-+-+ +-+ +-+ +-+-+-+ +-+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#15= 3,5,7,11,13,15,17,19,21,23,27,29,31 +    \n",
        "    \"|-+-----+-+-----+ +-----+ +-----+ |\",    \n",
        "    \"|H: : : : : : : : |               |\",#17= 1,3,5,7,9,11,13,15,17 -     \n",
        "    \"|-+-----+-+-----+ +-----+ +-----+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : :W| |\",#19= 3,5,7,11,13,15,17,19,21,23,27,29,31 + \n",
        "    \"| +-+ +-+-+-+ +-+ +-+ +-+-+-+ +-+ |\",    \n",
        "    \"|   | : : : : | | | | : : : : |   |\",#21= 5,7,9,11,13,17,21,23,25,27,29 +     \n",
        "    \"| +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#23= 3,5,7,9,11,13,15,17,19,21,23,25,27,29,31 +\n",
        "    \"| +-----+ +-----+ +-----+ +-----+ |\",    \n",
        "    \"|       | : : : : : : : : |       |\",#25= 9,11,13,15,17,19,21,23,25 -   \n",
        "    \"| +-----+ +-----+-+-----+ +-----+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#27= 3,5,7,9,11,13,15,19,21,23,25,27,29,31 +    \n",
        "    \"| +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ |\",    \n",
        "    \"|   | : : : : |     | : : : : |   |\",#29= 5,7,9,11,13,21,23,25,27,29 -    \n",
        "    \"| +-+ +-+-+-+ +-+ +-+ +-+-+-+ +-+ |\",    \n",
        "    \"| | : : | | : : | | : : | | : : | |\",#31= 3,5,7,11,13,15,19,21,23,27,29,31 -  \n",
        "    \"| +-----+ +-----+ +-----+ +-----+ |\",    \n",
        "    \"| : : : : : : : : : : : : : : : : |\",\n",
        "    \"+---------------------------------+\",\n",
        " ]\n",
        "\n",
        "P = {}\n",
        "\n",
        "class Maze(discrete.DiscreteEnv):\n",
        "    \"\"\"\n",
        "   \n",
        "    Destinations:\n",
        "    - W(ater)\n",
        "    - H(ome)\n",
        " \n",
        "    Actions:\n",
        "    There are 5 discrete deterministic actions:\n",
        "    - 0: move down\n",
        "    - 1: move up\n",
        "    - 2: move right\n",
        "    - 3: move left\n",
        "    - 4: drink water (press button)\n",
        "    \n",
        " \n",
        "    Rewards:\n",
        "    -100 for crash a wall\n",
        "    -10,000 for going outside the maze  \n",
        "    -100 for being outside the maze\n",
        "    -100 for pressing button outside water place\n",
        "    -1 default per-step\n",
        "    -exponential function for times in home, without water or without having 'food'\n",
        "    -1 for being in known place and +100 for being in a new place\n",
        "    +quadratic function for times between drinking or eating \n",
        "\n",
        " \n",
        "    Rendering:\n",
        "    - blue: mouse\n",
        "    - magenta: destination\n",
        " \n",
        "    state space is represented by:\n",
        "        (mouse_row, mouse_col, time_in_Maze, time_in_WOWater, time_in_Home, un_explored_Place)\n",
        "    \"\"\"\n",
        " \n",
        "    metadata = {\"render.modes\": [\"human\", \"ansi\"]}\n",
        "    buttonpressed = False\n",
        "    dest=[19,31]  #water place\n",
        "    home=[17,1]   #Home\n",
        "    desc = np.asarray(MAP, dtype=\"c\")\n",
        "\n",
        "    locs = locs = [(0, 0), (19, 31)]\n",
        "\n",
        "    num_states = 2178000\n",
        "    num_rows = 33\n",
        "    num_columns = 33\n",
        "\n",
        "    timeMaze =10\n",
        "    timeWOWater=10\n",
        "    timeHome=10\n",
        "    unExplored=2\n",
        "\n",
        "    max_row = num_rows - 2\n",
        "    max_col = num_columns - 2\n",
        "\n",
        "    initial_state_distrib = np.zeros(num_states+1)\n",
        "    num_actions = 5\n",
        "\n",
        "    done=False\n",
        "\n",
        "    taxi_loc=[0,0]\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.desc = np.asarray(MAP, dtype=\"c\")\n",
        " \n",
        "        self.locs = locs = [(0, 0), (19, 31)]\n",
        " \n",
        "        num_states = 2178000\n",
        "        num_rows = 33\n",
        "        num_columns = 33\n",
        "        timeMaze =10\n",
        "        timeWOWater=10\n",
        "        timeHome=10\n",
        "        unExplored=2\n",
        "        home=[17,1]\n",
        "        max_row = num_rows - 2\n",
        "        max_col = num_columns - 2\n",
        "        self.initial_state_distrib = np.zeros(num_states+1)\n",
        "        num_actions = 5\n",
        "        \n",
        "        self.P = {\n",
        "            state: {action: [] for action in range(self.num_actions)}\n",
        "            for state in range(self.num_states)\n",
        "        }\n",
        "      \n",
        "        done=False\n",
        "        taxi_loc=[0,0]\n",
        "\n",
        "\n",
        "    def inicial(self):    #function to fill P table \n",
        "          for row in range(self.num_rows):\n",
        "              for col in range(self.num_columns):\n",
        "                for timeM in range(self.timeMaze):\n",
        "                  for timeWOW in range(self.timeWOWater):\n",
        "                    for timeH in range(self.timeHome):\n",
        "                        for unExp in range(self.unExplored):\n",
        "\n",
        "                          state = self.encode(row, col,timeM,timeWOW,timeH, unExp)\n",
        "                          self.initial_state_distrib[state] += 1\n",
        "                    \n",
        "                          for action in range(self.num_actions):\n",
        "                        \n",
        "                              new_row, new_col = row, col\n",
        "                              reward = -1  # default reward \n",
        "                              done = False\n",
        "                              taxi_loc = [row, col]\n",
        "                              buttonpressed = False\n",
        "\n",
        "                              reward = reward - 1*((np.exp(timeM/2)/15)*1000-(np.exp(0/2)/15)*1000)       #reward for time in maze (without food)\n",
        "                              reward = reward - 1*((np.exp(timeWOW/2)/15)*1000-(np.exp(0/2)/15)*1000)     #reward for time without water\n",
        "                              reward = reward - 1*((np.exp(timeH/2)/15)*1000-(np.exp(0/2)/15)*1000)       #reward for staying at home\n",
        "\n",
        "                              if unExp == 0: #reward for exploration (+100 new place or -1 for being in a known place)\n",
        "                                reward = reward-1 \n",
        "                              else:\n",
        "                                reward = reward+100\n",
        "                           \n",
        "                              if action == 0 : #down\n",
        "                                if new_row in range(0,self.num_rows):\n",
        "                                  if self.desc[row+1,col] != b\"-\":\n",
        "                                    new_row = min(row + 2, self.max_row)\n",
        "                                  elif self.desc[row+1,col]  == b\"-\":\n",
        "                                    reward =reward-100                        #reward for crashing a wall\n",
        "                                    new_row =  row\n",
        "                                else:\n",
        "                                  reward =reward-10000                        #reward for going outside the maze\n",
        "                                  new_row =  row\n",
        "      \n",
        "                              elif action == 1 : #up\n",
        "                                if new_row in range(0,self.num_rows):\n",
        "                                  if self.desc[row-1,col] != b\"-\":\n",
        "                                    new_row = min(row - 2, self.max_row)\n",
        "                                  elif self.desc[row-1,col]  == b\"-\":\n",
        "                                    reward =reward -100                       #reward for crashing a wall\n",
        "                                    new_row =  row\n",
        "                                else:\n",
        "                                  reward =reward-10000                        #reward for going outside the maze\n",
        "                                  new_row =  row\n",
        "      \n",
        "                              if action == 2: #right\n",
        "                                if col in range(0,self.num_columns):\n",
        "                                  if self.desc[row, col + 1] == b\":\":\n",
        "                                    new_col = min(col + 2, self.max_col)\n",
        "                                  else:\n",
        "                                    reward = reward-100                       #reward for crashing a wall\n",
        "                                    new_col = col\n",
        "                                else:\n",
        "                                  reward =reward-10000                        #reward for going outside the maze\n",
        "                                  new_col =  col\n",
        "      \n",
        "                              elif action == 3: #left\n",
        "                                if col in range(0,self.num_columns):\n",
        "                                  if self.desc[row, col - 1] == b\":\":\n",
        "                                    new_col = min(col - 2, self.max_col)\n",
        "                                  else:\n",
        "                                    reward = reward-100                       #reward for crashing a wall\n",
        "                                    new_col = col\n",
        "                                else:\n",
        "                                  reward =reward-10000                        #reward for going outside the maze\n",
        "                                  new_col =  col  \n",
        "                            \n",
        "                              elif action == 4:  # press button\n",
        "\n",
        "                                if taxi_loc == self.dest: #at water place\n",
        "                                  reward = reward + (timeWOW**2/8-1)*100      #reward for drinking water as a function of time\n",
        "                                  if timeWOW in range(3,10):\n",
        "\n",
        "                                    buttonpressed=True\n",
        "                                    done = True\n",
        "                                 \n",
        "                                else:  # presses button that doesn't exist\n",
        "                                    reward = reward-100                       #reward for pressing a button that doesn't exist\n",
        "                      \n",
        "\n",
        "                                if taxi_loc == self.home: #at home\n",
        "                               \n",
        "                                    reward = reward + (timeM**2/8-1)*100      #reward for eating at home as a function of time\n",
        "                                    if timeM in range(3,10):\n",
        "                                      buttonpressed=True\n",
        "                                   \n",
        "                                else:\n",
        "                                    reward = reward-100                       #reward for pressing a button that doesn't exist\n",
        "                                    \n",
        "\n",
        "                              if state<0:\n",
        "                                print(state, ' ', self.decode(state))\n",
        "                              new_state = self.encode(\n",
        "                                  new_row, new_col,timeM,timeWOW,timeH, unExp\n",
        "                              )\n",
        "                              if taxi_loc in pos :    \n",
        "                                reward = reward -100                          #reward for being in a place outside the maze (pos is defined in next cell)\n",
        "                            \n",
        "      \n",
        "                              self.P[state][action].append((1.0, new_state, reward, done))\n",
        "                                      \n",
        "          self.initial_state_distrib /= self.initial_state_distrib.sum()\n",
        "          discrete.DiscreteEnv.__init__(\n",
        "              self, self.num_states, self.num_actions, self.P, self.initial_state_distrib\n",
        "          )\n",
        " \n",
        " \n",
        "        \n",
        "    def encode(self, taxi_row, taxi_col,timeMaze,timeWOWater,timeHome, unExplored):\n",
        "        i = int(taxi_row) \n",
        "        i *= 33\n",
        "        i += int(taxi_col) \n",
        "        i *= 10\n",
        "        i += timeMaze \n",
        "        i *= 10\n",
        "        i += timeWOWater \n",
        "        i *= 10\n",
        "        i += timeHome \n",
        "        i *= 2\n",
        "        i += unExplored\n",
        "        return int(i)\n",
        "\n",
        "    def decode(self,i):\n",
        "        out = []\n",
        "        out.append(i % 2)\n",
        "        i = i // 2\n",
        "        out.append(i % 10)\n",
        "        i = i // 10\n",
        "        out.append(i % 10)\n",
        "        i = i // 10\n",
        "        out.append(i % 10)\n",
        "        i = i // 10\n",
        "        out.append(i % 33)\n",
        "        i = i // 33\n",
        "        out.append(i)\n",
        "        assert 0 <= i < 33\n",
        "        return out[::-1]\n",
        "\n",
        " \n",
        "    def render(self, mode=\"human\"):\n",
        "        outfile = StringIO() if mode == \"ansi\" else sys.stdout\n",
        " \n",
        "        out = self.desc.copy().tolist()\n",
        "        out = [[c.decode(\"utf-8\") for c in line] for line in out]\n",
        "        taxi_row, taxi_col, algo, algo1, algo2, algo3= self.decode(self.s)\n",
        " \n",
        "        def ul(x):\n",
        "            return \"_\" if x == \" \" else x\n",
        " \n",
        "        if self.buttonpressed:\n",
        "            out[taxi_row][taxi_col] = utils.colorize(\n",
        "                out[taxi_row][ taxi_col], \"yellow\", highlight=True\n",
        "            )\n",
        "            self.buttonpressed=False\n",
        " \n",
        "        else:  # passenger in taxi\n",
        "            out[ taxi_row][taxi_col] = utils.colorize(\n",
        "                ul(out[taxi_row][taxi_col ]), \"blue\", highlight=True\n",
        "            )\n",
        " \n",
        "        di, dj = self.dest\n",
        "        out[di][dj ] = utils.colorize(out[ di][dj ], \"magenta\")\n",
        "        outfile.write(\"\\n\".join([\"\".join(row) for row in out]) + \"\\n\")\n",
        "        if self.lastaction is not None:\n",
        "            outfile.write(\n",
        "                \"  ({})\\n\".format(\n",
        "                    [\"Down\", \"Up\", \"Right\", \"Left\", \"Press Button\", \"Stand still\"][\n",
        "                        self.lastaction\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            outfile.write(\"\\n\")\n",
        " \n",
        "        # No need to return anything for human\n",
        "        if mode != \"human\":\n",
        "            with closing(outfile):\n",
        "                return outfile.getvalue()\n",
        " \n",
        "    def step1(self, s, a):\n",
        " \n",
        "        p, s1, r, d = self.P[s][a][0]\n",
        "        \n",
        "        self.s = s1\n",
        "        self.lastaction = a\n",
        "        \n",
        "        return p, s1, r, d\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeXi3_VrcD9b"
      },
      "source": [
        "\n",
        "#columns allowed in each row allowed\n",
        "posLoc = [\n",
        "          [3,5,7,11,13,15,19,21,23,27,29,31],\n",
        "          [5,7,9,11,13,21,23,25,27,29],\n",
        "          [3,5,7,9,11,13,15,19,21,23,25,27,29,31],\n",
        "          [ 9,11,13,15,17,19,21,23,25],\n",
        "          [3,5,7,9,11,13,15,17,19,21,23,25,27,29,31],\n",
        "          [5,7,9,11,13,17,21,23,25,27,29],\n",
        "          [3,5,7,11,13,15,17,19,21,23,27,29,31],\n",
        "\n",
        "          [1,3,5,7,9,11,13,15,17],\n",
        "\n",
        "          [3,5,7,11,13,15,17,19,21,23,27,29,31],\n",
        "          [5,7,9,11,13,17,21,23,25,27,29],\n",
        "          [3,5,7,9,11,13,15,17,19,21,23,25,27,29,31],\n",
        "          [9,11,13,15,17,19,21,23,25],\n",
        "          [3,5,7,9,11,13,15,19,21,23,25,27,29,31],\n",
        "          [5,7,9,11,13,21,23,25,27,29],\n",
        "          [3,5,7,11,13,15,19,21,23,27,29,31]\n",
        "          ]\n",
        "\n",
        "pos = []\n",
        "\n",
        "n_pos=[]\n",
        "for i in range(33):\n",
        "  for j in range(33):\n",
        "    n_pos.append([i,j])\n",
        "n_pos[162]\n",
        "\n",
        "n_pos2 = [i for i in n_pos if i not in pos]\n",
        "print(pos)\n",
        "print(n_pos2)\n",
        "\n",
        "pos=n_pos2   #pos are locations not allowed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YSDgyzBJDy7"
      },
      "source": [
        "import gym\n",
        "from sys import exit\n",
        "from PIL import Image\n",
        "from time import sleep, time\n",
        "\n",
        "env = Maze()\n",
        "env.inicial() #P table construction"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yvUValcn56N"
      },
      "source": [
        "#Q-learning\n",
        "\n",
        "import numpy as np\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "alpha = 0.01   # learning rate\n",
        "gamma = 0.6    #temporal discount rate\n",
        "epsilon = 0.7\n",
        "#epsilon-greedy strategy. At each step, \n",
        "#the agent will decide with probability  1−ϵ  to use the best action for the \n",
        "#state it is currently in by looking at the value function, otherwise just make a random choice\n",
        "\n",
        "row = 17\n",
        "col = 1\n",
        "timeM = 0\n",
        "timeWOW = 0\n",
        "timeH = 0\n",
        "unExp = 0\n",
        "realdone=0\n",
        "\n",
        "state = env.encode(row, col,timeM,timeWOW,timeH, unExp) #set initial state\n",
        "count = 0\n",
        "printea = True  #for printing results at different times\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "frames2 = []\n",
        "\n",
        "for i in range(1, 100001):\n",
        "    #every episode reset the state to initial \n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "\n",
        "    done = False\n",
        "    ready=False\n",
        "    row = 17\n",
        "    col = 1\n",
        "    timeM = 0\n",
        "    timeWOW = 0\n",
        "    timeH = 0\n",
        "    unExp = 0\n",
        "    realdone=0\n",
        "\n",
        "    #times for rewards are counted every XX steps\n",
        "    epocH=0\n",
        "    epocW=0\n",
        "    epocWOW = 0\n",
        "\n",
        "    loc =[]  #to save the known places\n",
        "    count = 0\n",
        "    state = env.encode(row, col,timeM,timeWOW,timeH, unExp) \n",
        "    env.s = state\n",
        "\n",
        "    while not ready:\n",
        "\n",
        "        row, col,timeM,timeWOW,timeH, unExp = env.decode(state)\n",
        "        \n",
        "        \n",
        "        if random.uniform(0, 1) < epsilon:     #relation between exploring or exploiting\n",
        "            action = env.action_space.sample() #Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state]) #Exploit learned values\n",
        "        \n",
        "\n",
        "        prob, next_state, reward, done = env.step1(state, action)\n",
        "        new_row, new_col,new_timeM, new_timeWOW,new_timeH, new_unExp = env.decode(next_state)\n",
        "\n",
        "\n",
        "        if [row,col] == [17,1]:  #counting time at home\n",
        "          epocH +=1\n",
        "          if epocH !=0 and epocH%20==0:\n",
        "            if timeH ==9:  #maximun time\n",
        "              timeH=9\n",
        "            else:\n",
        "              timeH+=1\n",
        "        else: \n",
        "          epocH =0\n",
        "          timeH =0\n",
        "          \n",
        "        \n",
        "        if [row,col] != [19,31]:  #counting time without water\n",
        "          epocWOW +=1\n",
        "          if epocWOW!=0 and epocWOW%20==0:\n",
        "            if timeWOW == 9:   #maximun time\n",
        "              timeWOW=9\n",
        "            else:\n",
        "              timeWOW+=1\n",
        "        else: \n",
        "          if done:  #reset time only when pressing button\n",
        "            epocWOW=0\n",
        "            timeWOW=0\n",
        "            \n",
        "\n",
        "        \n",
        "        if [row,col]!=[17,1]:  #counting time without returning home (food)\n",
        "          epocM +=1\n",
        "          if epocM!=0 and epocM%20==0:\n",
        "            if timeM == 9:   #maximun time\n",
        "              timeM=9\n",
        "            else:\n",
        "              timeM+=1\n",
        "        else: \n",
        "          if timeM > 6 and len(loc)>5:\n",
        "            loc=[]   #reset known places \n",
        "          epocM =0\n",
        "          timeM=0\n",
        "          \n",
        "               \n",
        "        if [row,col] in loc:   #new place unExp = 1\n",
        "          unExp =0\n",
        "        else:\n",
        "          unExp =1\n",
        "          loc.append([row,col])\n",
        "\n",
        "\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "        \n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        if reward < -100:\n",
        "          penalties += 10\n",
        "        if done:\n",
        "          realdone+=1 \n",
        "\n",
        "        if printea == True:  #for saving printed frames\n",
        "          frames2.append({\n",
        "                'frame': env.render(mode='ansi'),\n",
        "                'state': state,\n",
        "                'action': action,\n",
        "                'reward': reward,\n",
        "                'timeM':timeM,\n",
        "                'timeH':timeH,\n",
        "                'timeWOW':timeWOW,\n",
        "                'realdone':realdone\n",
        "                }\n",
        "            ) \n",
        "          \n",
        "\n",
        "        state = env.encode(new_row, new_col,timeM,timeWOW,timeH, unExp) \n",
        "        \n",
        "        epochs += 1\n",
        "        \n",
        "        if realdone== 5:  #after drinking water 5 times, the episode ends\n",
        "          \n",
        "          ready=True\n",
        "\n",
        "\n",
        "    printea =False #only save the frames of some episodes\n",
        "    if i % 100 == 0:\n",
        "        printea = True\n",
        "        print(f\"Episode: {i}\")\n",
        "        print(realdone)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2kixN_R652"
      },
      "source": [
        "#Performance after Q training\n",
        "\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 100\n",
        "frames3 = [] \n",
        "\n",
        "for _ in range(episodes):\n",
        "\n",
        "    #set initial state every episode\n",
        "\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    done = False\n",
        "    row = 17\n",
        "    col = 1\n",
        "    timeM = 0\n",
        "    timeWOW = 0\n",
        "    timeH = 0\n",
        "    unExp = 0\n",
        "    ready = False\n",
        "    epocH=0\n",
        "    epocW=0\n",
        "    epocWOW = 0\n",
        "    realdone = 0\n",
        "    loc =[]\n",
        "    count = 0\n",
        "\n",
        "    state = env.encode(row, col,timeM,timeWOW,timeH, unExp) \n",
        "    env.s = state\n",
        "\n",
        "\n",
        "    while not ready:\n",
        "        row, col,timeM,timeWOW,timeH, unExp = env.decode(state)\n",
        "      \n",
        "        action = np.argmax(q_table[state])\n",
        "        prob, state, reward, done = env.step1(state, action)\n",
        "        new_row, new_col,new_timeM,new_timeWOW,new_timeH, new_unExp = env.decode(state)\n",
        "        \n",
        "        \n",
        "        if [row,col] == [17,1]:\n",
        "          epocH +=1\n",
        "          if epocH !=0 and epocH%10==0:\n",
        "            if timeH ==9:\n",
        "              timeH=9\n",
        "            else:\n",
        "              timeH+=1\n",
        "        else: \n",
        "          epocH =0\n",
        "          timeH =0\n",
        "          \n",
        "        \n",
        "        if [row,col] != [19,31]:\n",
        "          epocWOW +=1\n",
        "          if epocWOW!=0 and epocWOW%10==0:\n",
        "            if timeWOW == 9:\n",
        "              timeWOW=9\n",
        "            else:\n",
        "              timeWOW+=1\n",
        "        else: \n",
        "          if done:\n",
        "            epocWOW =0\n",
        "            timeWOW=0\n",
        "\n",
        "        \n",
        "        if [row,col]!=[17,1] :\n",
        "          epocM +=1\n",
        "          if epocM!=0 and epocM%10==0:\n",
        "            if timeM == 9:\n",
        "              timeM=9\n",
        "            else:\n",
        "              timeM+=1\n",
        "        else: \n",
        "          if timeM > 7 and len(loc)>5:\n",
        "            loc=[]\n",
        "          epocM =0\n",
        "          timeM=0 \n",
        "          \n",
        "          \n",
        "          \n",
        "        \n",
        "        if [row,col] in loc:\n",
        "          unExp =0\n",
        "        else:\n",
        "          unExp =1\n",
        "          loc.append([row,col])\n",
        "\n",
        "        \n",
        " \n",
        "\n",
        "        frames3.append({\n",
        "              'frame': env.render(mode='ansi'),\n",
        "              'state': state,\n",
        "              'action': action,\n",
        "              'reward': reward,\n",
        "              'timeM':timeM,\n",
        "              'timeH':timeH,\n",
        "              'timeWOW':timeWOW,\n",
        "              'realdone':realdone\n",
        "              }\n",
        "          )\n",
        "        if done:\n",
        "          realdone+=1\n",
        "         \n",
        "        epochs+=1\n",
        "\n",
        "        if realdone == 5:\n",
        "          ready = True\n",
        "        if reward < -100:\n",
        "            penalties += 10\n",
        "        state = env.encode(new_row, new_col,timeM,timeWOW,timeH, unExp)\n",
        "    print(f\"Results after {_+1} episodes:\")\n",
        "    print(f\"Average timesteps per episode: {total_epochs / (_+1)}\")\n",
        "    print(f\"Average penalties per episode: {total_penalties / (_+1)}\")\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uTyDw0rc9eL"
      },
      "source": [
        "#printing frames from the maze\n",
        "\n",
        "from time import sleep, time\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Image\n",
        "\n",
        "def print_frames2(frames, t):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\",'\\t\\t',f\"Time in Maze: {frame['timeM']}\")\n",
        "        print(f\"State: {frame['state']}\",'\\t\\t',f\"Time in Home: {frame['timeH']}\")\n",
        "        print(f\"Action: {frame['action']}\",'\\t\\t',f\"Time without water: {frame['timeWOW']}\")\n",
        "        print(f\"Reward: {int(frame['reward'])}\",'\\t\\t',f\"Drink water: {frame['realdone']}\")\n",
        "        sleep(t)\n",
        "\n",
        "\n",
        "#printing frames of the performance (t is time waiting for the next frame)\n",
        "print_frames2(frames3, t=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
